<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Penalised methods for genetic data</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
    <script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
    <link href="libs/font-awesome-5.0.12/css/fontawesome-all.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">




class: title-slide center middle inverse

&lt;br&gt;

# Session 4.&lt;br&gt;Penalised methods for genetic data analysis

&lt;br&gt;

## Florian Priv√©

### King's College London -- May 20, 2019

&lt;br&gt;

&lt;br&gt;

**Slides:** `https://privefl.github.io/R-presentation/penalised-genetics.html`

---

class: inverse, center, middle

# Introduction to penalized models

---

## Multiple linear regression

We want to solve

`$$y = \beta_0 + \beta_1 G_1 + \cdots + \beta_p G_p + \gamma_1 COV_1 + \cdots + \gamma_q COV_q + \epsilon~.$$`
--

Let `\(\beta = (\beta_0, \beta_1, \dots, \beta_p, \gamma_1, \dots, \gamma_q)\)` and `\(X = [1; G_1; \dots;G_p; COV_1; \dots; COV_q]\)`, then

`$$y = X \beta + \epsilon~.$$`

--

This is equivalent to minimizing

`$$||y - X \beta||_2^2 =  ||\epsilon||_2^2~,$$`
--

whose solution is 

`$$\beta = (X^T X)^{-1} X^T y~.$$`

--

&lt;br&gt;

**What is the problem when analyzing genotype data?**

--

`$$n &lt; p$$`

---

## Penalization term -- `\(L_2\)` regularization

&lt;br&gt;

Instead, we can minimize

`$$||y - X \beta||_2^2 + \lambda ||\beta||_2^2~,$$`
--

whose solution is 

`$$\beta = (X^T X + \lambda I)^{-1} X^T y~.$$`

--

&lt;br&gt;

This is the L2-regularization ("**ridge**", Hoerl and Kennard, 1970); **it shrinks coefficients `\(\beta\)` towards 0**.

.footnote[https://doi.org/10.1080/00401706.1970.10488634]

---

## Penalization term -- `\(L_1\)` regularization

&lt;br&gt;

Instead, we can minimize

`$$||y - X \beta||_2^2 + \lambda ||\beta||_1~,$$`
--

which does not have any closed form but can be solved using iterative algorithms.

--

&lt;br&gt;

This is the L1-regularization ("**lasso**", Tibshirani, 1996); **it forces some of the coefficients to be equal to 0** and can be used as a means of variable selection, leading to sparse models.

.footnote[https://doi.org/10.1111/j.2517-6161.1996.tb02080.x]

---

## Penalization term -- `\(L_1\)` and `\(L_2\)` regularization

&lt;br&gt;

Instead, we can minimize

`$$||y - X \beta||_2^2 + \lambda (\alpha ||\beta||_1 + (1 - \alpha) ||\beta||_2^2)~,$$`
--

which does not have any closed form but can be solved using iterative algorithms ( `\(0 \le \alpha \le 1\)` ).

--

&lt;br&gt;

This is the L1- and L2-regularization ("**elastic-net**", Zou and Hastie, 2005); it is a compromise between the two previous penalties.

.footnote[https://doi.org/10.1111/j.1467-9868.2005.00503.x]

---

## Advantages and drawbacks of penalization

--

### Advantages

- Make it possible to solve the linear problem

- Generally prevents overfitting (because of smaller effects)

--

### Drawback

- Add at least one hyper-parameter ( `\(\lambda\)` ) that needs to be chosen and another one if using the elastic-net regularization ( `\(\alpha\)` )

--

### Alternative

- Select a few variables before fitting the linear model (e.g. using marginal significance/p-values); heuristic: `\(p = n / 10\)`

---

## Binary outcome (case-control)

**Penalized logistic regression**: minimize

`$$L(\lambda, \alpha) = \underbrace{ -\sum_{i=1}^n \left( y_i \log\left(z_i\right) + (1 - y_i) \log\left(1 - z_i\right) \right) }_\text{Loss function}$$`
    
`$$+ \underbrace{ \lambda \left((1-\alpha)\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization} ~,$$`

where `\(z_i=1/\left(1+\exp\left(-(\beta_0 + X_{(i)}^T\beta)\right)\right)\)`, `\(X_i\)` denotes the genotypes and covariates (e.g. principal components) for individual `\(i\)`, and `\(y_i\)` is the disease status for individual `\(i\)`.

---

class: inverse, center, middle

# Code in practice

---

## Data

Download [data](https://github.com/privefl/bigsnpr/raw/master/data-raw/public-data.zip) and unzip files. 

I store those files in a directory called "tmp-data" here.


```r
# Convert the bed/bim/fam data to the format used 
# by packages {bigstatsr} and {bigsnpr}.
bigsnpr::snp_readBed("tmp-data/public-data.bed")
```


```r
# Access the genotype matrix and the phenotype
data &lt;- bigsnpr::snp_attach("tmp-data/public-data.rds")
G &lt;- data$genotypes
X &lt;- G[]  ## 560 MB
y &lt;- data$fam$affection - 1
```


```r
# Divide the indices in training/test sets
set.seed(1)
n &lt;- nrow(X)
ind.train &lt;- sample(n, 400)
ind.test &lt;- setdiff(1:n, ind.train)
```

---

## Multiple logistic model

&lt;br&gt;


```r
mod &lt;- glm(y[ind.train] ~ X[ind.train, ], family = "binomial")
```

```
Error: cannot allocate vector of size 128.4 Gb
In addition: Warning message:
glm.fit: algorithm did not converge 
```

&lt;br&gt;

### Prioritizing on marginal p-values


```r
library(bigstatsr)
gwas &lt;- big_univLogReg(G, y[ind.train], ind.train = ind.train,
                       ncores = nb_cores())
pval &lt;- predict(gwas, log10 = FALSE)
ind &lt;- order(pval)
```

---

## Multiple logistic model after selection


```r
df &lt;- data.frame(y = y, X.sub = I(X[, ind[1:40]]))
mod &lt;- glm(y ~ X.sub, data = df, subset = ind.train, 
           family = "binomial")
pred &lt;- predict(mod, df[ind.test, ], type = "response")
AUCBoot(pred, y[ind.test])
```

```
      Mean       2.5%      97.5%         Sd 
0.68731950 0.59291869 0.77324362 0.04612472 
```

--


```r
library(ggplot2)
ggplot(data.frame(pheno = as.factor(y[ind.test]), pred = pred)) + 
  geom_density(aes(pred, fill = pheno), alpha = 0.3)
```

&lt;img src="penalised-genetics_files/figure-html/unnamed-chunk-7-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

---

## Penalized models using {glmnet}


```r
library(glmnet)
```


```r
mod2 &lt;- glmnet(X[ind.train, ], y[ind.train], family = "binomial")
pred2 &lt;- predict(mod2, X[ind.test, ], type = "response")
```




```r
plot(mod2$lambda[-1], apply(pred2, 2, AUC, target = y[ind.test])[-1],
     xlim = rev(range(mod2$lambda)), log = "x", pch = 20,
     xlab = expression(lambda~~(log-scale)), ylab = "AUC (on test set)")
```

&lt;img src="penalised-genetics_files/figure-html/unnamed-chunk-11-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

---

## From underfitting to overfitting


```r
plot(mod2$dev.ratio, pch = 20, log = "y")
```

&lt;img src="penalised-genetics_files/figure-html/unnamed-chunk-12-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

---

class: inverse, center, middle

# Evaluating models

---

## Dividing in training / test sets

What is the issue with this?

What would be a better solution?

--




**K-fold cross-validation** (here, K = 5):

&lt;img src="crossval.png" width="70%" style="display: block; margin: auto;" /&gt;

---

## A possible implementation


```r
set.seed(1)
K &lt;- 5
test_grp &lt;- sample(rep_len(1:K, n))
head(test_grp, 20)
```

```
 [1] 4 3 5 5 2 3 3 5 2 4 4 2 1 5 5 1 5 3 1 5
```

```r
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Replace with your preferred model
  df &lt;- data.frame(y = y, x = X[, 1])
  mod &lt;- glm(y ~ x, data = df, subset = ind.train, family = "binomial")
  pred &lt;- predict(mod, df[ind.test, ], type = "response")
  AUC(pred, y[ind.test])
})
```

```
[1] 0.4917044 0.4717244 0.4361781 0.5601521 0.4949495
```

---

## Using cross-validation for parameter(s) selection


```r
aucs &lt;- sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Replace with your preferred model
  mod &lt;- glmnet(X[ind.train, ], y[ind.train], family = "binomial")
  pred &lt;- predict(mod, X[ind.test, ], type = "response")
  apply(pred, 2, AUC, target = y[ind.test])
})
```


```r
plot(rowMeans(aucs)[-1], pch = 20, ylab = "Mean AUC")
```

&lt;img src="penalised-genetics_files/figure-html/unnamed-chunk-17-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

---

## Both parameter selection and evaluation

How to do this?

We already used all data to find best parameter `\(\lambda\)`..

--

**Nested** cross-validation (here 5x2 nested CV):

&lt;img src="nested-crossval.png" width="75%" style="display: block; margin: auto;" /&gt;

---

## Using the internal cross-validation of {glmnet}

&lt;br&gt;

Nested 5x3 cross-validation:


```r
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Penalized logistic regression with cross-validation
  mod_cv &lt;- cv.glmnet(X[ind.train, ], y[ind.train],
                      family = "binomial", nfolds = 3)
  pred &lt;- predict(mod_cv, X[ind.test, ], type = "response", 
                  s = "lambda.1se")
  AUC(pred, y[ind.test])
})
```

```
[1] 0.6602564 0.6798088 0.7269017 0.6788909 0.7082362
```

&lt;br&gt;

However, it is starting to take some time to run.

---

class: inverse, center, middle

# A slightly different approach in {bigstatsr}

---

## Cross-Model Selection and Averaging (CMSA)

&lt;img src="https://raw.githubusercontent.com/privefl/paper2-PRS/master/figures/simple-CMSA.png" width="75%" style="display: block; margin: auto;" /&gt;

---

## CMSA in practice


```r
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Penalized logistic regression with CMSA
  mod_cmsa &lt;- big_spLogReg(G, y[ind.train], ind.train = ind.train, 
                           K = 3)
  pred &lt;- predict(mod_cmsa, G, ind.test)
  AUC(pred, y[ind.test])
})
```

```
[1] 0.7405732 0.7009160 0.6909091 0.6900716 0.6915307
```

--

&lt;br&gt;

Advantages:

- faster (mainly because of early-stopping criterion)

- memory efficient (because data is stored on disk)

So, can be applied to huge genotype data.

---

class: inverse, center, middle

# Time to practice yourself

---

## Data

Download [data](https://github.com/privefl/bigsnpr/raw/master/data-raw/public-data.zip) and unzip files. 

I store those files in a directory called "tmp-data" here.


```r
# Convert the bed/bim/fam data to the format used 
# by packages {bigstatsr} and {bigsnpr}.
bigsnpr::snp_readBed("tmp-data/public-data.bed")
```


```r
# Access the genotype matrix and the phenotype
data &lt;- bigsnpr::snp_attach("tmp-data/public-data.rds")
G &lt;- data$genotypes
X &lt;- G[]  ## Access as standard R matrix of 560 MB
y &lt;- data$fam$affection - 1
```


```r
# Let us use the same folds for evaluation in cross-validation
set.seed(1)
n &lt;- nrow(G)
K &lt;- 5
test_grp &lt;- sample(rep_len(1:K, n))
```

---

## Make the best prediction of disease

You can use any model you like.

In addition to the genotype data we already used, you can use external summary statistics provided in `tmp-data/public-data-sumstats.txt`.

--

&lt;br&gt;

For example,


```r
library(bigstatsr)
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Penalized logistic regression with CMSA
  mod_cmsa &lt;- big_spLogReg(G, y[ind.train], ind.train = ind.train, 
                           K = 4, ncores = nb_cores())
  pred &lt;- predict(mod_cmsa, G, ind.test)
  AUC(pred, y[ind.test])
})
```

```
[1] 0.7232278 0.6933493 0.7213358 0.7110912 0.7482517
```

---

class: inverse, center, middle

# Correction

## Some possible solutions

---

## Train elastic-net instead of only lasso


```r
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Penalized logistic regression with CMSA
  mod_cmsa &lt;- big_spLogReg(G, y[ind.train], ind.train = ind.train, 
                           K = 4, ncores = nb_cores(),
                           alphas = 10^(-(0:4)))
  pred &lt;- predict(mod_cmsa, G, ind.test)
  AUC(pred, y[ind.test])
})
```

```
[1] 0.7586727 0.7120669 0.7187384 0.7204830 0.7288267
```

---

## Use summary statistics to prioritize variables


```r
sumstats &lt;- bigreadr::fread2("tmp-data/public-data-sumstats.txt")
pval &lt;- sumstats$p
conf &lt;- pmax(-log10(pval), 1)
```

--

&lt;br&gt;

Apply a different penalization factor to each variable:


```r
sapply(1:K, function(k) {
  ind.test  &lt;- which(test_grp == k)
  ind.train &lt;- which(test_grp != k)
  ## Penalized logistic regression with CMSA
  mod_cmsa &lt;- big_spLogReg(G, y[ind.train], ind.train = ind.train, 
                           K = 4, ncores = nb_cores(),
                           alphas = 10^(-(0:4)), pf.X = 1 / conf)
  pred &lt;- predict(mod_cmsa, G, ind.test)
  AUC(pred, y[ind.test])
})
```

```
[1] 0.7914781 0.7224213 0.7239332 0.7218247 0.7482517
```

---

class: inverse, center, middle

# Thanks!

&lt;br&gt;

&lt;br&gt;

<i class="fab  fa-twitter "></i> [privefl](https://twitter.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-github "></i> [privefl](https://github.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-stack-overflow "></i> [F. Priv√©](https://stackoverflow.com/users/6103040/f-priv%c3%a9)

.footnote[Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
